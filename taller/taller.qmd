---
execute:
  echo: true
format:
  revealjs:
    width: 1245
    height: 700
    menu: false
    controls: true
    transition: fade
    auto-stretch: false
    embed-resources: false
    toc: false
    center: true
    slide-number: false
    preview-links: false
    output-file: "taller"
    theme:
        - simple

---

##
::: {style="position: absolute; left: 700px; top: 550px; width:2000px; background-color: #ffffff; padding: 10px; border-radius: 5px;"}
[Taller de Python + IA para todos]{style="font-size: 20px; margin: 0px;"} <br>
[¡Haz tu propio ChatGPT!]{style="font-size: 30px; font-weight: bold; margin: 0px"} <br>
[Sebastián Flores, Francisco Alfaro, Valeska Canales]{style="font-size: 25px;"}
:::

::: {.notes}
.
:::

---

## ¿Qué dicen los diarios de la IA?

![](images/alarmismo.png){fig-align="center" .fragment}

---

## SI presten atención al hombre tras la cortina

{{< video videos/tras_la_cortina.mp4 >}}

---

## Parte 1

La ilusión de la continuidad

---

El computador & la ilusión de la continuidad.
bits, just bits. 
Imagen: bits + context/conventions -> representación

---

todo es discretos: numeros, colores, gráficos, sonidos, etc etc.

---

Alta fidelidad no es continuidad. Pero es una muy buena aproximación.

---

No necesitamos la realidad, necesitamos una buena aproximación. Suficiente para engañar a los sentidos.

Otro ejemplo: una película. Ojo humano es muy malo para detectar el frame rate. Una pelicula de 24 fps es suficiente para engañar al ojo humano.


---

## Parte 2

El computador parlanchín

---

¿Cómo representar una palabra?

---

Depende...
Si solo queremos transmitir texto (sin interpretar - semántica), basta con representar cada letra con una secuencia de bits, y almacenarla. Listo.

---

Si quieres poder interpretar el texto, necesitamos una mejor REPRESENTACIÓN.
texto -> tokens -> embeddings
(ejemplo)


---

## Actividad 2.1

* Actividad: Ir a [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
* Objetivo: Evaluar distintos textos, en distintos idiomas.
  * Ejemplo 1: *La informática,​ también llamada computación, es el área de la ciencia que se encarga de estudiar la administración de métodos, técnicas y procesos con el fin de almacenar, procesar y transmitir información y datos en formato digital.*
  * Ejemplo 2: *Computing is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes the study and experimentation of algorithmic processes, and the development of both hardware and software. Computing has scientific, engineering, mathematical, technological, and social aspects.*
* Tiempo: 5 minutos

Nota: Definiciones extraídas de wikipedia.

---

## Aprendizajes de Actividad 2.1

* Palabra != Token
* Cada token tiene un identificador único
* En inglés,  100 tokens ~= 75 palabras. 
* 2 palabras pueden ser idénticas pero tener distinto token

---

¿LLM?
LLM = Large Language Model = Grandes Modelos de Lenguaje

---

## Diagrama técnico 

Diagrama de funcionamiento de un LLM que se filtró de OpenAI:

[¡¡¡No difundir!!!]{.fragment}

![](images/LLM_words.gif){fig-align="center" .fragment}

---

Predecir la próxima palabra a partir de las anteriores.
Mostrar imagen de cómo va avanzando la creación de la respuesta, palabra por palabra.

---

Ojo: no es que el LLM "piense" o "sabe" lo que está haciendo. Es sólo una representación.

---

Ojo 2: es estadística aplicada! 

---

Ojo 3: Se predice token a token. No hay paralelismo, no se puede predecir el siguiente token mientras los anteriores no se han predicho. Es super secuencial.

---

OJo 4: El LLM no tiene memoria. Siempre empieza a predecir desde el mismo estado inicial.

---

Comparar con una multiplicación de matrices. La matriz no recuerda que ya hizo multiplicaciones antes.

---

¿Cómo se entrena un LLM?

---

Corpus de texto y mucho dinero o muchas gpus.
¿Que se obtiene? Muchas grandes matrices! (depende de la arquitectura) - dar 1 ejemplo.

---

Esto significa que un LLM open source puede descargarse (son bits), y ejecutarse localmente - si tu hardware lo permite.

---

## Parte 3

¡Hazlo tu mismo!

---

## ¿Cómo podemos emular chatGPT?

Lo más importante es tener un LLM:

::: columns
::: {.column width="50%" .center}
Ejecutar localmente LLM: 

* Configuración compleja
* Hardware costoso
:::
::: {.column width="50%" .fragment}
Consumir una API de LLM  

* Simple
* Pagar lo que consumes
* Multiples proveedores y alternativas
:::
:::

---


## ¿API?
::: columns
::: {.column width="50%"}
Imagen con una analogía de la API
:::
::: {.column width="50%" .fragment .center}

:::
:::
---

## Actividad 1

* Actividad: Ir a [citt](citt)
* Objetivo: Lograr que el bot responda "con personalidad"
* Tiempo: 5 minutos

---

## Aprendizajes de la Actividad 1

* El LLM responde en función del prompt.
* El prompt puede pedir cualquier cosa.
  
---

## Actividad 2

* Actividad: Ir a [citt](citt)
* Objetivo: Hacer 2 preguntas:
  * ¿Qué animal da leche y dice mu? 
  * ¿Que come ese animal?
* ¿El LLM tiene memoria?
* Tiempo: 5 minutos

--- 

## Aprendizajes de la Actividad 2

* Separar en contexto y pregunta permite imponer una "personalidad" o ciertas características.
* El chatbot no tiene memoria.

--- 

## ¿Porqué chatGPT si tiene memoria? {.fragment}

¿Cómo solucionarían ustedes este problema?

Respuesta: Muy simple: Pasemosle la historia de la conversación en cada prompt.
- Opción 1: Pasarle todo el texto.
- Opción 2: Pasarle un resumen de la conversación.

---

##  ¿Temperatura?

¿Qué es la temperatura?

Rpa: Que tan aleatoria es la elección del siguiente token.

---

## Actividad 3

* Actividad: Ir a [citt](citt)
* Objetivo: Hacer 2 preguntas:
  * ¿Qué animal da leche y dice mu? 
  * ¿Que come ese animal?
* ¿El LLM tiene memoria?
* Tiempo: 5 minutos

---

## Aprendizajes de la Actividad 3

* El LLM necesita todo el contexto e historia en el prompt.
* Las APIs agregan muchas opciones para manejar todo esto convenientemente.

---

## Conclusión

* LLMs no son magia: es tecnología.
* Cualquiera puede comenzar a crear soluciones con LLMs.
* Conocer como funcionan LLMs permite usarlos mejor.
* Existen recursos gratuitos para aprender y jugar.

---

## ¿Storytelling?
::: columns
::: {.column width="50%"}
![](images/fire.jpeg){fig-align="center"}
:::
::: {.column width="50%" .fragment .center}
&#32;<br><br><br><br>
Lorem Ipsum
:::
:::

---

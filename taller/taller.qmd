---
execute:
  echo: true
format:
  revealjs:
    width: 1245
    height: 700
    menu: false
    controls: true
    transition: fade
    auto-stretch: false
    embed-resources: true
    toc: false
    center: true
    slide-number: false
    preview-links: false
    output-file: "taller"
    theme:
        - simple

---

##
::: {style="position: absolute; left: 700px; top: 550px; width:2000px; background-color: #ffffff; padding: 10px; border-radius: 5px;"}
[Taller de Python + IA para todos]{style="font-size: 20px; margin: 0px;"} <br>
[¬°Haz tu propio ChatGPT!]{style="font-size: 30px; font-weight: bold; margin: 0px"} <br>
[Sebasti√°n Flores, Francisco Alfaro, Valeska Canales]{style="font-size: 25px;"}
:::

::: {.notes}
.
:::

---

## ¬øQu√© dicen los diarios de la IA?

![](images/alarmismo.png){fig-align="center" .fragment}

---

## SI presten atenci√≥n al hombre tras la cortina

{{< video videos/tras_la_cortina.mp4 >}}

---

::: {.callout-tip title="Idea"}
Toda tecnolog√≠a suficientemente avanzada parece magia.

[**Arthur C. Clarke**]{style="text-align: right;"}
:::

---

## Parte 1

La ilusi√≥n de la continuidad

---

## Desaf√≠o

¬øQu√© contiene la siguiente cadena de bits?

[00000000]{style="font-size: 80px; margin: 0px; color: white"}
[00101010]{style="font-size: 80px; margin: 0px;"}

---

[00000000]{style="font-size: 80px; margin: 0px; color: white"}
[00101010]{style="font-size: 80px; margin: 0px;"}

[Podr√≠a ser el n√∫mero 42 escrito en binario...]{.fragment}

---

[00000000]{style="font-size: 80px; margin: 0px; color: white"}
[00101010]{style="font-size: 80px; margin: 0px;"}

[Podr√≠a ser el car√°cter `*` en la convenci√≥n ascii...]{.fragment}

---

[00000000]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00101010]{style="font-size: 80px; margin: 0px;"}
[00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}

[Podr√≠a ser parte de un n√∫mero decimal, 0.4523 o $\pi$...]{.fragment}


---

[10000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00100001]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[01000111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00001000]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00101010]{style="font-size: 80px; margin: 0px;"}
[01000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[11111111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[11001101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[01000111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[00000101]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}
[01110111]{style="font-size: 80px; margin: 0px; color:#D3D3D3"}

[Podr√≠a ser parte de un archivo multimedia (video, imagen, audio, etc.)...]{.fragment}

---

En el computador **TODO** se representa con bits.

`representaci√≥n` `=` `bits` `+` `contexto` 

[Eso significa que todo es discreto.  
No existe ni el infinito ni lo continuo.]{.fragment}

---

Alta fidelidad no es continuidad.

![](code/derivada_5.png){fig-align="center"}

---

Alta fidelidad no es continuidad.

![](code/derivada_7.png){fig-align="center"}

---

Alta fidelidad no es continuidad.

![](code/derivada_9.png){fig-align="center"}

---

Alta fidelidad no es continuidad.

![](code/derivada_11.png){fig-align="center"}

---

Alta fidelidad no es continuidad.

![](code/derivada_21.png){fig-align="center"}

---

Alta fidelidad no es continuidad. [Pero puede ser suficiente...]{.fragment fragment-index=1}

![](code/derivada_31.png){fig-align="center"}

---

No necesitamos la realidad, necesitamos una buena aproximaci√≥n. Suficiente para enga√±ar a los sentidos.

![](images/celuloide.jpg){width=50% fig-align="center" .fragment}

[Una pel√≠cula de 24 FPS es suficiente para enga√±ar al ojo humano.]{.fragment}


---

## Moraleja de Parte 1

* Ninguna representaci√≥n en el computador es perfecta.
* LLMs no son perfectos, pero no necesitamos que lo sean.

---

## Parte 2

El computador parlanch√≠n

---

¬øC√≥mo representar una palabra?

---

## Representaci√≥n textual

Si solo queremos transcribir texto, basta con representar cada letra con una secuencia de bits, y almacenarla.

::: columns
::: {.column style="font-size: 24px;" .fragment .center}
ASCII

* 1 byte (8 bits): 128 car√°cteres posibles
* 0 (48) ... 9 (57)
* A (65) ... Z (90)
* a (97) ... z (122) 
* Problema: Faltan muchos car√°cteres: √ë, √±, √°, √©, √≠, √≥, √∫, u
:::
::: {.column style="font-size: 24px;" .fragment .center}
UTF-8

* 1 a 4 bytes (8 a 32 bits)
* Mantiene ASCII sin cambios
* Permite representar alfabetos latinos, griego, cir√≠lico, copto, armenio, hebreo, √°rabe, sir√≠aco, thaana, y n'ko, adem√°s de caracteres chinos, japoneses y coreanos. 
* Incluye emojis üòÅ, simbolos ‚úÖ y mil cosas m√°s üóø
:::
:::

---

## Representaci√≥n sem√°ntica

Sem√°ntica: relativo al **significado** de las palabras.

Si quieres que el computador pueda interpretar el sentido de cada palabra, es necesario almacenar cada palabra como un todo. No puede descomponerse en sus letras.

[Necesitamos una mejor REPRESENTACI√ìN.]{.fragment}

---

## Actividad 2.1

* Actividad: Ir a [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
* Objetivo: Evaluar distintos textos, en distintos idiomas.
  * Ejemplo 1: *La inform√°tica,‚Äã tambi√©n llamada computaci√≥n, es el √°rea de la ciencia que se encarga de estudiar la administraci√≥n de m√©todos, t√©cnicas y procesos con el fin de almacenar, procesar y transmitir informaci√≥n y datos en formato digital.*
  * Ejemplo 2: *Computing is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes the study and experimentation of algorithmic processes, and the development of both hardware and software. Computing has scientific, engineering, mathematical, technological, and social aspects.*
* Tiempo: 5 minutos

Nota: Definiciones extra√≠das de wikipedia.

---

## Aprendizajes de Actividad 2.1

* Palabra != Token
* Cada token tiene un identificador √∫nico
* En ingl√©s,  100 tokens ~= 75 palabras. 
* 2 palabras pueden ser id√©nticas pero tener distinto token

---

## ¬øLLM?

LLM = Large Language Model = Grandes Modelos de Lenguaje

---

## Diagrama t√©cnico de un LLM

Diagrama de funcionamiento de un LLM que se filtr√≥ de OpenAI:

[¬°¬°¬°No difundir!!!]{.fragment}

![](images/LLM_words.gif){fig-align="center" width=150% .fragment}

---

## Actividad 2.2

* Actividad: Ir a [https://huggingface.co/spaces/alonsosilva/NextTokenPrediction](https://huggingface.co/spaces/alonsosilva/NextTokenPrediction)
* Objetivo: Observar la lista de token que se muestran como posible continuaci√≥n del texto.
* Tiempo: 5 minutos

---

## Aprendizajes de Actividad 2.1

* El LLM no reflexiona sobre la pr√≥xima palabra. 
* El LLM sugiere los tokens que estad√≠sticamente son m√°s probables.
* Se predice token a token. No hay paralelismo, no se puede predecir el siguiente token mientras los anteriores no se han predicho. Es super secuencial.
* El LLM no tiene memoria. Siempre empieza a predecir desde el mismo estado inicial.

::: {.notes}
Comparar con una multiplicaci√≥n de matrices. La matriz no recuerda que ya hizo multiplicaciones antes.
:::

---

## El negocio de los LLMs

* Los LLMs hoy en d√≠a tienen billones de par√°metros: 1,000,000,000,000
* Cada par√°metro se determina en un proceso de entrenamiento basado en enormes conjuntos de texto (esencialmente TODO el internet y libros escritos).
* Entrenar una LLM requiere muchas horas de uso de tarjetas gr√°ficas (GPUs).

Esto significa que un LLM open source puede descargarse (son bits), y ejecutarse localmente - si tu hardware lo permite.

---

## El negocio de los LLMs

No existe solo chatGPT (OpenAI): todos quieren un pedazo de la torta:

::: columns
::: {.column width="50%" .fragment .center}
Los de pago:

* GPT-4 (OpenAI)
* Gemini (Google)
* Claude (Anthropic)
* ...
:::
::: {.column width="50%" .fragment .center}
Los de c√≥digo abierto:

* Llama (Meta)
* Qwen (Baidu)
* DeepSeek (China)
* ...
:::
:::

[Y est√°n quienes no desarrollan pero entregan LLM como un servicio: Amazon (Bedrock), OpenRouter, etc.]{.fragment}

---

## Parte 3

¬°Hazlo tu mismo!

---

## ¬øC√≥mo podemos emular chatGPT?

Lo m√°s importante es tener un LLM:

::: columns
::: {.column width="50%" .center}
Ejecutar localmente LLM: 

* Configuraci√≥n compleja
* Hardware costoso
:::
::: {.column width="50%" .fragment}
Consumir una API de LLM  

* Simple
* Pagar lo que consumes
* Multiples proveedores y alternativas
:::
:::

---

## Actividad 1

* Actividad: Ir a [https://cittripio.streamlit.app/](https://cittripio.streamlit.app/)
* Objetivo: Lograr que el bot responda "con personalidad"
* Tiempo: 5 minutos

---

## Aprendizajes de la Actividad 1

* El LLM responde en funci√≥n del prompt.
* El prompt puede pedir cualquier cosa.
  
---

## Actividad 2

* Actividad: Ir a [https://cittripio.streamlit.app/v2](https://cittripio.streamlit.app/v2)
* Objetivo: Hacer 2 preguntas:
  * ¬øQu√© animal da leche y dice mu? 
  * ¬øQue come ese animal?
* ¬øEl LLM tiene memoria?
* Tiempo: 5 minutos

--- 

## Aprendizajes de la Actividad 2

* Separar en contexto y pregunta permite imponer una "personalidad" o ciertas caracter√≠sticas.
* El chatbot no tiene memoria.

--- 

## ¬øPorqu√© chatGPT si tiene memoria? {.fragment}

¬øC√≥mo solucionar√≠an ustedes este problema?

Respuesta: Muy simple: Pasemosle la historia de la conversaci√≥n en cada prompt.

- Opci√≥n 1: Pasarle todo el texto.
- Opci√≥n 2: Pasarle un resumen de la conversaci√≥n.

---

##  ¬øTemperatura?

¬øQu√© es la temperatura?

Respuesta: 

* Es un par√°metro que controla que tan aleatoria es la elecci√≥n del siguiente token.
* Temperatura = 0: Muy determinista.
* Temperatura = 1: Muy aleatorio.

---

## Actividad 3

* Actividad: Ir a [https://cittripio.streamlit.app/v2](https://cittripio.streamlit.app/v2)
* Objetivo 1: Lograr que cittripio le responda a Luke Skywalker que es su padre.
* Objetivo 2: Cambiar la personalidad de cittripio por cualquier otro personaje (no necesariamente de Star Wars).
* Tiempo: 5 minutos

---

## Aprendizajes de la Actividad 3

* El LLM necesita tener como input todo el contexto e historia en el prompt.
* Las APIs agregan muchas opciones para simplificar y manejar todo esto convenientemente.

---

## Conclusi√≥n

* LLMs no son magia: es tecnolog√≠a.
* Cualquiera puede comenzar a crear soluciones con LLMs.
* Conocer como funcionan LLMs permite usarlos mejor.
* Existen muchos recursos gratuitos para aprender y jugar.

---

## Preguntas

QR de encuesta: https://forms.gle/???

---
